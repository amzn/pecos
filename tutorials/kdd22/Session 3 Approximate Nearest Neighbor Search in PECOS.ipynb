{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5073aac",
   "metadata": {},
   "source": [
    "# Approximate Nearest Neighbor (ANN) Search in PECOS \n",
    "\n",
    "PECOS provides the efficient approach for **approximate nearest neighbor (ANN) search**. More specifically, after training an hierarchical navigable small world (HNSW) model (or buildling the **PECOS-HNSW indexer**) with a corpus of vectors, PECOS supports to efficiently infer top-K approximated nearest indexed vectors for an arbitrary query vector. In this part of the tutorial, we will demonstrate how to use PECOS-HNSW tackle the approximate nearest neighbor (ANN) search problem and how to integrate HNSW with PECOS XMR models.\n",
    "\n",
    "#### HNSW at a glimpse\n",
    "The search procedure of HNSW can be summarized as:\n",
    "* traverse from top layer (course-grain graph, long-range link) to bottom layer (fine-grain graph, short-range link)\n",
    "* best first search traversal on each graph, where the best candidate serves as initial to next layer\n",
    "<div> <br/><img src=\\\"imgs/hnsw-example.png\\\" width=\\\"80%\\\"/> </div>\n",
    "\n",
    "\n",
    "## Highlight of PECOS-HNSW\n",
    "\n",
    "* Support both sparse and dense input features\n",
    "* Support SIMD instructions (SSE, AVX256, and AVX512)\n",
    "* Modularity implementation\n",
    "\n",
    "## Comparison of PECOS and NMSLIB on the sparse data\n",
    "\n",
    "#### Disclaimer \n",
    "The benchmarking results listed in this notebook are based on an `r5dn-24xlarge` AWS instance with 96 Intel(R) Xeon(R) Platinum 8259CL CPUs @ 2.50GHz. With distinct environments, the magnitude of improvments could be also different.\n",
    "\n",
    "#### Results\n",
    "* We compare two implementations of HNSW: `PECOS` and `NMSLIB` on a sparse dataset (i.e., RCV1).\n",
    "* For RCV1, the instances in training/test set are `781,265` and `23,149`, respectively. The feature dimension is `47,236`.\n",
    "* The HNSW index is constructed under `M=16` and `efConstruction=500`.\n",
    "* From the table below, we see that, under similar Recall@10, `PECOS` achieves `[88%,93%]` speedup compared to the `NMSLIB` package.\n",
    "\n",
    "| M=16, efC=500 |           |                         |    HNSW (PECOS)    |           |                         |    HNSW (NMSLIB)   | speedup (PECOS/NMSLIB) |\n",
    "|:-------------:|:---------:|:-----------------------:|:------------------:|:---------:|:-----------------------:|:------------------:|:----------------------------:|\n",
    "|      efS      | Recall@10 | Throughput (#query/sec) | Latency (ms/query) | Recall@10 | Throughput (#query/sec) | Latency (ms/query) |                              |\n",
    "|            10 |    0.7733 |                5250.297 |             0.1905 |    0.7790 |                2710.256 |             0.3690 |                       93.72% |\n",
    "|            20 |    0.8545 |                3677.292 |             0.2719 |    0.8581 |                1924.505 |             0.5196 |                       91.08% |\n",
    "|            40 |    0.9043 |                2409.959 |             0.4149 |    0.9055 |                1271.085 |             0.7867 |                       89.60% |\n",
    "|            80 |    0.9325 |                1508.349 |             0.6630 |    0.9326 |                 800.999 |             1.2484 |                       88.31% |\n",
    "|           120 |    0.9434 |                1125.047 |             0.8889 |    0.9426 |                 597.873 |             1.6726 |                       88.17% |\n",
    "|           200 |    0.9533 |                 763.752 |             1.3093 |    0.9523 |                 404.518 |             2.4721 |                       88.81% |\n",
    "|           400 |    0.9621 |                 433.872 |             2.3048 |    0.9608 |                 229.553 |             4.3563 |                       89.01% |\n",
    "|           600 |    0.9657 |                 305.747 |             3.2707 |    0.9644 |                 161.879 |             6.1775 |                       88.87% |\n",
    "|           800 |    0.9678 |                 237.651 |             4.2078 |    0.9663 |                 124.806 |             8.0124 |                       90.42% |\n",
    "\n",
    "## Hands-on Tutorial\n",
    "\n",
    "The life cycle of a PECOS-HNSW model consists of two stages:\n",
    "\n",
    "* building the indexer (training)\n",
    "* inference (testing).\n",
    "\n",
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "140a0d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-15 21:03:07--  https://archive.org/download/pecos-dataset/ann-benchmarks/rcv1-angular-47236.tar.gz\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ia802308.us.archive.org/21/items/pecos-dataset/ann-benchmarks/rcv1-angular-47236.tar.gz [following]\n",
      "--2022-07-15 21:03:07--  https://ia802308.us.archive.org/21/items/pecos-dataset/ann-benchmarks/rcv1-angular-47236.tar.gz\n",
      "Resolving ia802308.us.archive.org (ia802308.us.archive.org)... 207.241.228.48\n",
      "Connecting to ia802308.us.archive.org (ia802308.us.archive.org)|207.241.228.48|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 317972212 (303M) [application/octet-stream]\n",
      "Saving to: ‘rcv1-angular-47236.tar.gz’\n",
      "\n",
      "100%[======================================>] 317,972,212 11.0MB/s   in 40s    \n",
      "\n",
      "2022-07-15 21:03:47 (7.68 MB/s) - ‘rcv1-angular-47236.tar.gz’ saved [317972212/317972212]\n",
      "\n",
      "rcv1-angular-47236/\n",
      "rcv1-angular-47236/X.trn.npz\n",
      "rcv1-angular-47236/X.tst.npz\n",
      "rcv1-angular-47236/Y.tst.npy\n"
     ]
    }
   ],
   "source": [
    "! wget https://archive.org/download/pecos-dataset/ann-benchmarks/rcv1-angular-47236.tar.gz\n",
    "! tar -zxvf ./rcv1-angular-47236.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46dc982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_trn  781265 n_tst   23149 data_dim   47236\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pecos.utils import smat_util\n",
    "X_trn = smat_util.load_matrix(\"./rcv1-angular-47236/X.trn.npz\").astype(np.float32)\n",
    "X_tst = smat_util.load_matrix(\"./rcv1-angular-47236/X.tst.npz\").astype(np.float32)\n",
    "Y_tst = smat_util.load_matrix(\"./rcv1-angular-47236/Y.tst.npy\")\n",
    "print(\"n_trn {:7d} n_tst {:7d} data_dim {:7d}\".format(\n",
    "    X_trn.shape[0], X_tst.shape[0], X_trn.shape[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb73c619",
   "metadata": {},
   "source": [
    "### Training Indexer\n",
    "\n",
    "To train a PECOS-HNSW model, training parameters need to be defined in an object of HNSW.TrainParams as the argument train_params. The key parameters of training a PECOS-HNSW model include:\n",
    "* `M` (default 32): The maximum number of edges per node for each layer. A larger M leads to a larger model size and greater memory consumption. Higher/lower M are more suitable for high/low dimensional data or the pursue of high/low recall.\n",
    "* `efC` (default 100): The size of the priority queue for best first search in construction. `efC` can be considered as the trade-off between efficiency and accuracy for indexing. A higher `efC` results in longer construction time but better quality of indexing.\n",
    "* `metric_type` (default ip): The distance metric type for ANN search. PECOS-HNSW currently supports Euclidean distance (`l2`); and inner product (`ip`)\n",
    "* `threads` (default -1): The number of threads for training, or -1 to use all available cores.\n",
    "\n",
    "The parameters for inference can be also decided as the argument pred_params during model construction so that the model can be directly applied for inference without further parameter designation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "553aaf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW Indexer | M 32 efC 100 metric ip | time(s) 11.980276823043823\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pecos.ann.hnsw import HNSW\n",
    "\n",
    "M, efC = 32, 100\n",
    "metric = \"ip\"\n",
    "train_params = HNSW.TrainParams(\n",
    "    M=M,\n",
    "    efC=efC,\n",
    "    metric_type=metric,\n",
    "    threads=-1,\n",
    ")\n",
    "start_time = time.time()\n",
    "model = HNSW.train(X_trn, train_params=train_params, pred_params=None)\n",
    "print(\"HNSW Indexer | M {} efC {} metric {} | time(s) {}\".format(\n",
    "    M, efC, metric, time.time() - start_time),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a150c44",
   "metadata": {},
   "source": [
    "### Save and Load Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf7905f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"./rcv1.pecos-hnsw.index\"\n",
    "model.save(model_folder)\n",
    "del model\n",
    "model = HNSW.load(model_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1af6ee7",
   "metadata": {},
   "source": [
    "### Inference and Evaluation\n",
    "\n",
    "To conduct inference with a train HNSW model, prediction parameters need to be defined in an object of HNSW.PredParams as the argument pred_params. The key parameters of inference with a PECOS-HNSW model include:\n",
    "\n",
    "* `efS` (default 100): The size of the priority queue for best first search during inference. Similar to efC, efS can be considered as the trade-off between search efficiency and accuracy. A higher efS results in more accurate results with slower speed. efS is required to be greater than topk.\n",
    "* `topk` (default 10): The number of approximate nearest neighbor to be returned. \n",
    "* `threads` (default -1): The number of searchers for parallel inference, -1 to use all available searchers.\n",
    "\n",
    "The predict function derives the search results based on a query matrix of shape (# of data points for inference, # of dimentions) and `pred_params`, as well as searchers. The argument `ret_csr` (default `true`) decides the format of returned results as:\n",
    "\n",
    "* If `ret_csr` is false, the returned results would be two matrices of shape (# of data points, topk), which indicate the topk indices in the training corpus and the corresponding distances for each testing instance.\n",
    "* If `ret_csr` is true, the returned results would be a  [Compressed Sparse Row (CSR) matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) of shape (# of data points, # of points in the training corpus). Each row contains sorted topk distance values at the corresponding columns (i.e., indices in training corpus). The data for each row (i.e., `data[indptr[i]:indptr[i + 1]]`) are also sorted by the distance values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25e31d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Time = 15.7988 seconds.\n"
     ]
    }
   ],
   "source": [
    "pred_params = HNSW.PredParams(efS=100, topk=10)\n",
    "searchers = model.searchers_create(num_searcher=1)\n",
    "start_time = time.time()\n",
    "indices, distances = model.predict(\n",
    "    X_tst,\n",
    "    pred_params=pred_params,\n",
    "    searchers=searchers,\n",
    "    ret_csr=False,\n",
    ")\n",
    "pred_time = time.time() - start_time\n",
    "print(f\"Prediction Time = {pred_time:.4f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce9aefa",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38401700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(neighbors, true_neighbors):\n",
    "    total = 0\n",
    "    for gt_row, row in zip(true_neighbors, neighbors):\n",
    "        total += np.intersect1d(gt_row, row).shape[0]\n",
    "    return total / true_neighbors.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b6d72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HNSW inference | R@10 0.9025 Throughput(q/s) 1465.236 latency(ms/q)   0.6825\n"
     ]
    }
   ],
   "source": [
    "recall = compute_recall(indices, Y_tst)\n",
    "throughput = indices.shape[0] / pred_time\n",
    "latency = 1.0 / throughput * 1000.\n",
    "print(f\"HNSW inference | R@10 {recall:.4f} Throughput(q/s) {throughput:8.3f} latency(ms/q) {latency:8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75880f0d",
   "metadata": {},
   "source": [
    "## Recall vs Throughput Trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bd7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pecos(X_trn, X_tst, Y_tst):\n",
    "    metric = \"ip\"\n",
    "    M_list = [16]\n",
    "    efC = 500\n",
    "    topk = 10\n",
    "    efS_list = [10, 20, 40, 80, 120, 200, 400, 600, 800]\n",
    "    for M in M_list:\n",
    "        train_params = HNSW.TrainParams(M=M, efC=efC, metric_type=metric, threads=-1)\n",
    "        start_time = time.time()\n",
    "        model = HNSW.train(X_trn, train_params=train_params, pred_params=None)\n",
    "        print(\"Indexer | M {} efC {} metric {} | train time(s) {}\".format(\n",
    "            M, efC, metric, time.time() - start_time)\n",
    "        )\n",
    "        \n",
    "        for efS in efS_list:\n",
    "            pred_params = HNSW.PredParams(efS=efS, topk=topk)\n",
    "            searchers = model.searchers_create(num_searcher=1)\n",
    "            \n",
    "            start_time = time.time()\n",
    "            indices, distances = model.predict(X_tst, pred_params=pred_params, searchers=searchers, ret_csr=False)\n",
    "            pred_time = time.time() - start_time\n",
    "            \n",
    "            recall = compute_recall(indices, Y_tst)\n",
    "            throughput = indices.shape[0] / pred_time\n",
    "            latency = 1.0 / throughput * 1000.\n",
    "            print(\"inference | efS {:3d} R@10 {:.4f} Throughput(q/s) {:8.3f} latency(ms/q) {:8.4f}\".format(\n",
    "                efS, recall, throughput, latency)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b4af0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexer | M 16 efC 500 metric ip | train time(s) 46.87919640541077\n",
      "inference | efS  10 R@10 0.7733 Throughput(q/s) 5250.297 latency(ms/q)   0.1905\n",
      "inference | efS  20 R@10 0.8545 Throughput(q/s) 3677.292 latency(ms/q)   0.2719\n",
      "inference | efS  40 R@10 0.9043 Throughput(q/s) 2409.959 latency(ms/q)   0.4149\n",
      "inference | efS  80 R@10 0.9325 Throughput(q/s) 1508.349 latency(ms/q)   0.6630\n",
      "inference | efS 120 R@10 0.9434 Throughput(q/s) 1125.047 latency(ms/q)   0.8889\n",
      "inference | efS 200 R@10 0.9533 Throughput(q/s)  763.752 latency(ms/q)   1.3093\n",
      "inference | efS 400 R@10 0.9621 Throughput(q/s)  433.872 latency(ms/q)   2.3048\n",
      "inference | efS 600 R@10 0.9657 Throughput(q/s)  305.747 latency(ms/q)   3.2707\n",
      "inference | efS 800 R@10 0.9678 Throughput(q/s)  237.651 latency(ms/q)   4.2078\n"
     ]
    }
   ],
   "source": [
    "run_pecos(X_trn, X_tst, Y_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58276b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Appendix: Install PECOS and NMSLIB\n",
    "\n",
    "### Install via Conda \n",
    "```bash\n",
    "conda create -n pecos-hnsw-tutorial python=3.8\n",
    "conda activate pecos-hnsw-tutorial\n",
    "\n",
    "pip install pyarrow pandas ipython jupyterlab\n",
    "```\n",
    "\n",
    "### Install PECOS from Source\n",
    "\n",
    "We will install PECOS from source with the -march=native flag to optimize the best SIMD instruction available in your machine. More details available in https://github.com/amzn/pecos#installation-from-source\n",
    "\n",
    "```bash\n",
    "# prerequisite, assuming amazon linux 2 \n",
    "sudo yum -y install python3 python3-devel python3-distutils python3-venv && sudo yum -y groupinstall 'Development Tools' \n",
    "sudo amazon-linux-extras install epel -y\n",
    "sudo yum install openblas-devel -y\n",
    "# pecos with -march=native flag\n",
    "git clone https://github.com/amzn/pecos\n",
    "cd pecos\n",
    "PECOS_MANUAL_COMPILE_ARGS=\"-march=native\" python -m pip install  --editable .\n",
    "```\n",
    "\n",
    "### Install NMSLIB from Source\n",
    "\n",
    "We follow the install guide [install guide](https://github.com/erikbern/ann-benchmarks/blob/master/install/Dockerfile.nmslib) from ANN-Benchmark to install NMSLIB from source for the best performance.\n",
    "\n",
    "```bash\n",
    "# pre-requisite, assuming amazon linux 2\n",
    "sudo yum -y install cmake boost-devel eigen3-devel\n",
    "git clone https://github.com/searchivarius/nmslib.git\n",
    "cd nmslib/similarity_search\n",
    "cmake . -DWITH_EXTRAS=1\n",
    "make -j4\n",
    "pip install pybind11\n",
    "cd ../python_bindings/\n",
    "python setup.py build\n",
    "python setup.py install\n",
    "python -c 'import nmslib'\n",
    "```\n",
    "\n",
    "### Install via Docker (as in ANN-Benchmkark)\n",
    "\n",
    "```bash\n",
    "# install some basic stuff\n",
    "sudo yum -y update\n",
    "sudo yum install -y git curl zip unzip vim gcc-c++ htop\n",
    "\n",
    "# https://docs.aws.amazon.com/AmazonECS/latest/developerguide/docker-basics.html\n",
    "# sudo yum update -y\n",
    "# sudo amazon-linux-extras install docker\n",
    "sudo service docker start\n",
    "sudo systemctl enable docker\n",
    "sudo usermod -a -G docker ec2-user\n",
    "docker info\n",
    "```\n",
    "\n",
    "### Install Docker Image\n",
    "\n",
    "```bash\n",
    "# install miniconda fist!\n",
    "conda create -n ann-benchmarks python=3.8\n",
    "conda activate ann-benchmarks\n",
    "\n",
    "# install ANN package supported by ann-benchmarks\n",
    "git clone https://github.com/erikbern/ann-benchmarks.git\n",
    "cd ann-benchmarks\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# install docker containers\n",
    "python -u install.py --algorithm faiss\n",
    "python -u install.py --algorithm hnswlib\n",
    "python -u install.py --algorithm n2\n",
    "python -u install.py --algorithm pecos\n",
    "python -u install.py --algorithm scann\n",
    "python -u install.py --algorithm ngt\n",
    "python -u install.py --algorithm nmslib\n",
    "python -u install.py --algorithm diskann\n",
    "python -u install.py --algorithm pynndescent\n",
    "\n",
    "# list all dockers\n",
    "docker image ls\n",
    "REPOSITORY TAG IMAGE ID CREATED SIZE\n",
    "ann-benchmarks-hnswlib latest 2e1ea8d11df7 2 hours ago 1.04GB\n",
    "ann-benchmarks-nmslib latest 1e094d3e96f7 3 hours ago 1.64GB\n",
    "ann-benchmarks-faiss latest 44e5bd15bfcd 5 hours ago 4.9GB\n",
    "ann-benchmarks-scann latest 5151abe3b09e 5 hours ago 2.76GB\n",
    "ann-benchmarks latest c2c612131da4 5 hours ago 938MB\n",
    "```\n",
    "\n",
    "### Enter Docker Env\n",
    "\n",
    "```bash\n",
    "EFS_DIR=/PATH/TO/pecos-hnsw-kdd22\n",
    "DOCKER_IMAGE=ann-benchmarks-nmslib\n",
    "\n",
    "docker run --rm -it -v ${EFS_DIR}:/home/app/ws \\\n",
    "    --entrypoint /bin/bash ${DOCKER_IMAGE}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b85b8a-f1a6-42f0-acf0-6596361e35b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pecos-from-wheel",
   "language": "python",
   "name": "pecos-from-wheel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
